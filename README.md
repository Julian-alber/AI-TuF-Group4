# Kurzfrist-Energieverbrauchs-Prognose und Deployment auf Edge-Ger√§ten

## Datenaufbereitung
Die Klasse "LoadAndPrepareData" beinhaltet alle Schritte, um die Roh-Zeitreihen aus der UCI ‚ÄûHousehold Power Consumption‚Äú‚ÄìDatei 
aufzubereiten und in ein f√ºr TensorFlow geeignetes Format zu bringen:
### 1. Hauptaufgaben
#### 1. Einlesen & Bereinigung
- Liest die Roh-Zeitreihen aus der .txt-Datei ein
- Kombiniert Date + Time zu einem Datetime Timestamp
- Interpoliert fehlende Werte entlang der Zeitachse 
- (Optional im Test-Modus) Einschr√§nkung des DataFrames auf die ersten N Zeilen zur schnelleren Validierung

#### 2. Resampling
- Aggregiert bei Bedarf min√ºtliche Messungen auf eine gr√∂bere Frequenz (z.B. auf Stundenwerte)

#### 3. Zeitreihen-Split
- Teilt die aggregierten Timeseries in Training / Validation / Test Splits im Verh√§ltnis 0.7, 0.15 und 0.15
- Wichtig: zeitlich getrennt, um Data-Leakage zu vermeiden

#### 4. Feature-Scaling
- Gew√§hrleistet √ºber Skalierung, dass alle Features (z. B. Global_active_power, Voltage, Sub_metering_*) in vergleichbarem Wertebereich liegen

#### 5. Sliding-Window-Erzeugung
- Baut ein Zeitbereich auf und zerlegt jeden Zeitbereich in Input der L√§nge window_size und Target der L√§nge horizon
- Durchmischt die Zeitbereiche und packt sie in Batches
- Liefert Tensorflow Dataset-Objekte, die direkt in weitere Tensorflow Methoden wie z.B. model.fit() eingesetzt werden k√∂nnen


### 2. Parameter der Klasse
| Parameter       | Beschreibung                                                                             |
|-----------------|------------------------------------------------------------------------------------------|
| `filepath`      | Pfad zur heruntergeladenen UCI-Datei (`.txt`)                                            |
| `na_values`     | List\[str], z. B. `["?"]`; strings, die als `NaN` gelesen werden                         |
| `resample_rule` | Resampling-Regel: `"h"` = Stunden, `"min"` = Minuten, etc.                               |
| `split_ratios`  | `(Train, Val, Test)` als Anteile der Gesamtl√§nge, Gesamtsumme = 1.0                      |
| `window_size`   | Anzahl vergangener Zeitschritte, die als Input ins Modell gehen                          |
| `horizon`       | Anzahl k√ºnftiger Zeitschritte, die das Modell vorhersagen soll                           |
| `batch_size`    | Anzahl Zeitbereiche pro Batch                                                            |
| `test_mode`     | Wenn `True`, werden nur `test_subset` Zeilen geladen ‚Äì ideal f√ºr schnelle Pipeline-Tests |


### 3. Methoden√ºbersicht
| Parameter                     | Beschreibung                                                                                                                                |
|-------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------|
| `load_and_clean()`            | Daten einlesen + Timestamp Aggregierung + Interpolation                                                                                     |
| `resample()`                  | Aggregation der Daten auf die gew√§hlte Frequenz                                                                                             |
| `split()`                     | Aufteilung der Zeitreihen in Trainings-, Validierungs- und Test-spilts                                                                      |
| `scale()`                     | MinMax-Skalierung der Daten                                                                                                                 |
| `make_tf_dataset(data_array)` | Aufbau von Zeitbereichen, Durschmischung, Zusammenfassung in Batches und transformation in Tensorflow format                                |
| `get_datasets()`              | Ruft alle notwendigen Datenaufarbeitungsschritte in der korrekten Reihenfolge auf und gibt Trainings-, Validierungs- und Test-spilts zur√ºck |
| `get_scaler()`                | Liefert den MinMaxScaler, f√ºr inverse Transformation von Vorhersagen                                                                        |


### 4. Beispiel Aufruf
```python
from LoadAndPrepareData import LoadAndPrepareData

loader = LoadAndPrepareData(
    filepath="data/household_power_consumption.txt",
    window_size=24,
    horizon=6,
    batch_size=32,
)

train_ds, val_ds, test_ds = loader.get_datasets()
scaler = loader.get_scaler()
```


## Modellauswahl
F√ºr die kurzfristige Prognose des Energieverbrauchs wurden drei Modell-Varianten ausgew√§hlt:

| Modell      | Beschreibung                                               | Vorteile                                                                                                  | Nachteile                                                                                         |
|-------------|------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|
| **LSTM**    | Long Short-Term Memory mit Speicher- und Vergessens-Tor    | ‚Ä¢ Sehr gute Modellierung langer Abh√§ngigkeiten<br>‚Ä¢ Gut etabliert in Forecast-Tasks                       | ‚Ä¢ Viele Parameter ‚Üí langsameres Training und Inferenz<br>‚Ä¢ H√∂herer Speicherbedarf beim Deployment |
| **Bi-LSTM** | Bidirektionales LSTM (Vorw√§rts- & R√ºckw√§rts-Pfad)          | ‚Ä¢ Nutzt Kontext aus Vergangenheit und ‚ÄûZukunft‚Äú<br>‚Ä¢ Oft bessere Genauigkeit bei zyklischen Mustern       | ‚Ä¢ Doppelter Rechen- und Speicheraufwand<br>‚Ä¢ Schwerer auf Edge-Ger√§ten einsetzbar                 |
| **GRU**     | Gated Recurrent Unit mit nur zwei Toren (Update & Reset)   | ‚Ä¢ Weniger Parameter ‚Üí schnelleres Training & Inferenz<br>‚Ä¢ Einfachere Komprimierung f√ºr Edge- Optimierung | ‚Ä¢ In Einzelf√§llen leicht niedrigere Genauigkeit als LSTM        n                                 |


## Hyperparameter-Suche
Die Hyperparameter-Suche erfolgt automatisiert mit **Keras Tuner** (Bayesian Optimization) und wird durch **Weights & Biases (W&B)** f√ºr ein umfassendes Experiment-Tracking erg√§nzt. Ziel ist es, optimale Modellarchitekturen und Trainingsparameter f√ºr die kurzfristige Energieverbrauchsprognose zu finden.

### Vorgehen

- **Suchstrategie:**  
  Es wird die *Bayesian Optimization* von Keras Tuner eingesetzt, um die besten Hyperparameter-Kombinationen effizient zu finden.  
- **Experiment-Tracking:**  
  Alle Versuche und Ergebnisse werden mit W&B protokolliert, inklusive Modellarchitektur, Metriken und Hyperparameter-Werten.

### Getunte Hyperparameter

Folgende Parameter werden im Suchraum variiert:

- **Modelltyp:**  
  - `model_type`: Auswahl zwischen `'lstm'`, `'gru'`, `'bidirectional_lstm'`
- **Rekurrente Layer:**  
  - Anzahl Units der ersten Schicht (`*_units_1`): 32‚Äì256  
  - Aktivierungsfunktion der ersten Schicht (`*_activation_1`): `'relu'` oder `'tanh'`  
  - `return_sequences_1`: Gibt an, ob eine zweite rekurrente Schicht folgt  
  - Anzahl Units der zweiten Schicht (`*_units_2`): 16‚Äì128 (falls zweite Schicht aktiv)  
  - Aktivierungsfunktion der zweiten Schicht (`*_activation_2`): `'relu'` oder `'tanh'`  
- **Dropout:**  
  - Nach jeder rekurrenten Schicht (`dropout_1`, `dropout_2`): 0.0‚Äì0.5 (Schrittweite 0.1)
- **Dense Layer:**  
  - Anzahl Units (`dense_units`): 16‚Äì128 (Schrittweite 16)
- **Optimierer:**  
  - Lernrate (`learning_rate`): 1e-4 ‚Äì 1e-2 (logarithmisch gesampelt)

### Ablauf der Suche

1. **Initialisierung:**  
   - Das Datenset wird vorbereitet und in Trainings-/Validierungsbatches aufgeteilt.
   - Die Eingabe- und Ausgabeformen werden automatisch erkannt.
2. **Tuning-Phase:**  
   - F√ºr jede Hyperparameter-Kombination wird ein Modell gebaut, trainiert und auf dem Validierungsset evaluiert.
   - Fr√ºhes Stoppen (`EarlyStopping`) und Lernraten-Reduktion (`ReduceLROnPlateau`) sorgen f√ºr effizientes Training.
   - Die besten Ergebnisse werden als Modell-Checkpoint gespeichert.
3. **Auswertung:**  
   - Die besten Hyperparameter werden √ºbernommen und das finale Modell erneut auf dem gesamten Trainingsdatensatz trainiert.
   - Alle Ergebnisse und Metriken werden in W&B gespeichert.

### Beispiel-Aufruf (CLI)

`python src/srv/TrainModel.py`

Optional kann mit `--test_mode` ein schneller Testlauf mit reduziertem Datensatz durchgef√ºhrt werden:

`python src/srv/TrainModel.py --test-mode`

### Wichtige Hinweise

- **Reproduzierbarkeit:**  
  Zufallsseed ist gesetzt, sodass Ergebnisse zwischen L√§ufen vergleichbar bleiben.
- **Ablageorte:**  
  - Tuner- und W&B-Resultate werden automatisch unter `/data/tuner_results` bzw. `/data/wandb` gespeichert.
  - Modell-Checkpoints werden im Verzeichnis `models/` abgelegt.
- **Experiment-Tracking:**  
  F√ºr eine √∂ffentliche W&B-Projektverwaltung kann das Projekt nach dem ersten Lauf in der Web-Oberfl√§che auf "public" gestellt werden.

## Visualisierung & Dashboard

Diese Anwendung erm√∂glicht die kurzfristige Prognose des Haushaltsstromverbrauchs auf Basis st√ºndlicher Zeitreihendaten. Die Applikation basiert auf TensorFlow, nutzt ein kompaktes `.tflite`-Modell und bietet √ºber ein interaktives Streamlit-Dashboard Einblicke in Vorhersagen und Modellg√ºte.

## üîÑ Datenaufbereitung

Die Klasse `LoadAndPrepareData` bereitet Rohdaten aus der `household_power_consumption.txt`-Datei f√ºr TensorFlow-kompatible Modelle auf. Hauptschritte:

### 1. Einlesen & Bereinigung

- Lese Roh-Zeitreihen (Date + Time) aus `.txt`
- Erzeuge kombinierten Datetime-Timestamp
- Interpoliere fehlende Werte
- (Optional) K√ºrze Datenmenge f√ºr schnelle Tests

### 2. Resampling

- Aggregiere Minutendaten zu Stundenwerten (`resample_rule="h"`)

### 3. Zeitreihen-Split

- Aufteilung in Training / Validation / Test (Verh√§ltnis: 70 / 15 / 15)
- Zeitlich strikt getrennt (Vermeidung von Data Leakage)

### 4. Feature Scaling

- Alle numerischen Features (z.‚ÄØB. `Global_active_power`, `Voltage`, ...) werden skaliert
- Ziel: vergleichbare Wertebereiche

### 5. Sliding Window

- Eingabefenster der L√§nge `window_size`, Zielwerte der L√§nge `horizon`
- TensorFlow Dataset-Objekte werden erstellt und gepackt

## Dashboard-Funktionen (`dashboard.py`)

Die Streamlit-App l√§dt Daten, f√ºhrt Vorhersagen durch und visualisiert Ergebnisse inkl. Feature-Wichtigkeit.

### Vorhersage

- Verwendung eines TensorFlow Lite Modells (`.tflite`)
- Prognose f√ºr 1‚Äì6 Stunden einstellbar

### üìà Visualisierung

- Vorhersage vs. Ground Truth als Liniendiagramm (Plotly)
- Darstellung der Metriken:
  - MAE
  - RMSE
  - R¬≤

### Feature Importance

- Berechnung der Attributionswerte mittels Integrated Gradients
- Anzeige als Heatmap (matplotlib)

## Edge-Optimierung

Die Edge-Optimierung besteht aus zwei Teilen. Zum einen die Konvertierung des Keras Modells in eine TensorFlow-Lite Modell und zum anderen die Ausf√ºhrung auf einem Edge-Ger√§t. In diesem Beispile wurde dabei ein RaspberryPi verwendet. 

### Ausf√ºhren der Konvertierung

Um die Konvertierung des Keras Modells auszuf√ºhren, muss der Code in der Datei `OptimizeModel.py` ausgef√ºhrt werden. Dabei werden dann die Methoden der Klasse `EdgeDeviceOptimization` und `TestOptimizedModels` ausgef√ºhrt. 

```
...\AI-TuF-Group4>python -m src.srv.OptimizeModel
```

### Ausf√ºhren der Demo auf dem Edge-Device

Um den Code auf einem EdgeDevice wie z.B. einem RaspberryPi auszuf√ºhren, werden alle Dateien aus dem Ordner `/edgeDevice` ben√∂tigt. Zus√§tzlich wird noch die Klasse `LoadAndPrepareData` und die Dateien `household_power_consumption.txt` und `prediction_input_example.csv` ben√∂tigt. Die Ordnerstruktur auf dem Zielger√§t muss gleich aufgebaut sein wie in diesem Projekt.
√úber das Modul `main` wird eine Demo gestartet, die Daten f√ºr den 01.06.2025 12:00 Uhr bis 17:00 Uhr vorhersagt.

```
...\AI-TuF-Group4>python -m src.edgeDevice.main
```

Zu Testzwecken, kann das Script auch auf einem normalen Rechner ausgef√ºhrt werden. Dabei wird dann anstatt der TensorFlow-Lite Runtime die normale TensorFlow integration verwendet. 

### Modelloptimierung mit EdgeDeviceOptimization

Die `EdgeDeviceOptimization` Klasse konvertiert trainierte Keras-Modelle (.h5) in optimierte TensorFlow Lite (TFLite) Formate f√ºr den Einsatz auf Edge-Ger√§ten. Dabei werden zwei verschiedene Optimierungsstufen angeboten:

#### Original Keras-Modell (.h5)
Das urspr√ºngliche trainierte Modell.

<img src="src/srv/models/best_model.h5.png" alt="Original Keras Model Architecture" width="150">

*Vollst√§ndige Keras-Architektur mit allen Trainings-Metadaten und Optimizer-Zust√§nden*

#### 1. Standard TFLite Konvertierung (ohne Optimierung)
```python
def __ConverToTfLiteWithoutOptimization(self):
```

<img src="src/edgeDevice/models/Vergleich_KerasModel_TFLiteModel.PNG" alt="Standard TFLite Model Architecture" width="600">

*TFLite-Modell nach Graph-Optimierung und Metadaten-Entfernung*

Bei der Konvertierung wird jede Layer des Keras-Modells in mehrere grundlegende TFLite operatoren zerlegt, die f√ºr die Ausf√ºhrung auf Embedded- oder Mobilger√§ten optimiert sind. 

- **Was passiert bei der Konvertierung**:
  - **Entfernung von Trainings-Metadaten**: Keras .h5-Dateien enthalten Optimizer-Zust√§nde, Gradienteninformationen und Trainingshistorie, die f√ºr die Inferenz nicht ben√∂tigt werden
  - **Graph-Optimierung**: Der Computational Graph wird vereinfacht - unn√∂tige Operationen werden entfernt, redundante Berechnungen zusammengefasst
  - **Operatoren-Mapping**: Keras/TensorFlow Operationen werden auf effizientere TFLite-Operatoren gemappt
  - **Speicher-Layout Optimierung**: Tensoren werden in einem f√ºr mobile Ger√§te optimierten Format gespeichert
  - **Format-Komprimierung**: Das bin√§re TFLite-Format ist kompakter als das HDF5-Format (.h5)

- **Vorteile**: 
  - **Deutlich kleinere Dateigr√∂√üe**: Typisch 50-70% Reduktion gegen√ºber .h5-Format durch Entfernung der Trainings-Metadaten
  - **Beibehaltung der urspr√ºnglichen Modellgenauigkeit**: Keine Pr√§zisionsverluste, da die Gewichte unver√§ndert bleiben
  - **Optimierte Inferenz**: Graph-Optimierungen f√ºhren zu schnellerer Ausf√ºhrung
  - **TFLite-Runtime Kompatibilit√§t**: Speziell f√ºr mobile/embedded Ger√§te entwickelte, schlanke Runtime (nur ~1MB vs. >100MB f√ºr TensorFlow)

#### 2. Quantisierte TFLite Konvertierung (mit Optimierung)
```python
def __ConvertToTfLiteWithOptimization(self):
```

<img src="src/edgeDevice/models/model_quantized.tflite.png" alt="Quantized TFLite Model Architecture" width="300">

*Quantisiertes TFLite-Modell mit 8-Bit Gewichten f√ºr maximale Kompression*

- **Was passiert**: Dynamische Quantisierung - Gewichte werden von 32-Bit Gleitkommazahlen (float32) auf 8-Bit Ganzzahlen (int8) reduziert
- **Vorteile**:
  - **Speichereffizienz**: Bis zu 75% kleinere Modellgr√∂√üe
  - **Schnellere Inferenz**: Integer-Operationen sind auf vielen Prozessoren schneller als Gleitkomma-Operationen  
  - **Geringerer Energieverbrauch**: Besonders wichtig f√ºr batteriebetriebene Edge-Ger√§te
  - **Bessere Cache-Nutzung**: Kleinere Modelle passen besser in den Prozessor-Cache
- **Nachteile**: Leichter Genauigkeitsverlust durch Rundungsfehler bei der Quantisierung

#### 3. Kompatibilit√§t f√ºr LSTM-Modelle
```python
self.modelConverter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,  # Standard TFLite-Operationen
    tf.lite.OpsSet.SELECT_TF_OPS     # TensorFlow-Operationen f√ºr dynamische Tensoren
]
self.modelConverter._experimental_lower_tensor_list_ops = False
```

**Warum ist diese Konfiguration bei LSTM-Modellen notwendig?**

- **Dynamische Sequenzl√§ngen**: LSTM-Schichten arbeiten mit variablen Eingabel√§ngen und internen Zust√§nden, die sich w√§hrend der Verarbeitung √§ndern. Standard TFLite-Operationen sind f√ºr statische Tensoren mit festen Dimensionen optimiert.

- **Unfolding-Problem**: LSTMs "entfalten" sich √ºber die Zeit - jeder Zeitschritt ist eine separate Operation. TFLite kann diese dynamischen Strukturen nicht nativ mit Standard-Operationen abbilden.

**Was bewirken die Konfigurationsoptionen?**

- **`tf.lite.OpsSet.SELECT_TF_OPS`**: Erm√∂glicht die Verwendung der urspr√ºnglichen TensorFlow-Operationen f√ºr komplexe LSTM-Berechnungen, die nicht in TFLite-Standard-Operationen konvertiert werden k√∂nnen.

- **`_experimental_lower_tensor_list_ops = False`**: Verhindert die automatische Konvertierung von TensorList-Operationen in Low-Level-Operationen, die bei LSTM-Modellen oft fehlschlagen oder ineffizient sind.

**Kompromiss**: Diese Konfiguration sorgt f√ºr Funktionalit√§t, macht das Modell aber etwas gr√∂√üer und weniger optimiert, da TensorFlow-Operationen ressourcenintensiver sind als native TFLite-Operationen. F√ºr Zeitreihenmodelle mit LSTM-Schichten ist dies jedoch meist der einzige Weg, um eine erfolgreiche Konvertierung zu gew√§hrleisten.

### Test der optimierten Modelle

#### Fehlermetriken und Vergleich
Der Vergleich zwischen Original- und optimierten Modellen erfolgt √ºber verschiedene Fehlermetriken:

**Mean Absolute Error (MAE)**:
- **Berechnung**: Durchschnitt der absoluten Differenzen zwischen Vorhersage und tats√§chlichen Werten
- **Interpretation**: Direkte Aussage √ºber den durchschnittlichen Fehler in den urspr√ºnglichen Einheiten (z.B. kWh)
- **Vorteil**: Leicht interpretierbar, nicht stark von Ausrei√üern beeinflusst

**Root Mean Square Error (RMSE)**:
- **Berechnung**: Quadratwurzel des Durchschnitts der quadrierten Fehler
- **Interpretation**: Bestraft gr√∂√üere Fehler st√§rker als MAE
- **Vorteil**: Zeigt die Variabilit√§t der Vorhersagefehler auf

**Mean Absolute Percentage Error (MAPE)**:
- **Berechnung**: Durchschnitt der prozentualen absoluten Abweichungen
- **Interpretation**: Relative Fehlermetrik in Prozent, unabh√§ngig von der Gr√∂√üenordnung der Werte
- **Vorteil**: Vergleichbarkeit zwischen verschiedenen Datens√§tzen und Zeitr√§umen

#### Modellgr√∂√üenvergleich
```python
def __CompareModelSizes(self):
```
Diese Methode vergleicht automatisch die Dateigr√∂√üen:
- **Original Keras-Modell (.h5)**: Vollst√§ndiges Modell mit allen Metadaten
- **Standard TFLite-Modell**: Bereits optimiert f√ºr mobile/embedded Ger√§te
- **Quantisiertes TFLite-Modell**: Maximale Kompression f√ºr ressourcenbeschr√§nkte Umgebungen

### Edge-Device Inferenz

#### EdgeDeviceInference Klasse
Die `EdgeDeviceInference` Klasse √ºbernimmt die Ausf√ºhrung der optimierten Modelle auf Edge-Ger√§ten:

**Flexible TFLite-Runtime Unterst√ºtzung**:
```python
try:
    import tflite_runtime.interpreter as tflite  # F√ºr Edge-Ger√§te
except ImportError:
    import tensorflow as tf  # Fallback f√ºr Development-Umgebungen
```

**Hauptfunktionen**:
- **Modell laden**: Initialisierung des TFLite-Interpreters
- **Tensoren allokieren**: Speicher f√ºr Ein- und Ausgabedaten reservieren
- **Inferenz ausf√ºhren**: Vorhersage mit Zeitmessung
- **Performance-Monitoring**: Ausgabe der Inferenzzeit f√ºr Optimierungsanalysen

#### Praktische Anwendung (main.py)
Die `main.py` demonstriert eine vollst√§ndige Inferenz-Pipeline:

1. **Datenvorverarbeitung**: 
   - Laden von Beispieldaten f√ºr zuk√ºnftige Zeitpunkte (01.06.2025 12:00-18:00)
   - Anwendung der gleichen Skalierung wie beim Training
   - Formatierung in die korrekte Eingabeform (window_size=24 Stunden)

2. **Vergleichende Vorhersagen**:
   - Ausf√ºhrung mit Standard-TFLite-Modell
   - Ausf√ºhrung mit quantisiertem TFLite-Modell

3. **Ergebnisvisualisierung**:
   - Farbkodierte Ausgabe f√ºr verschiedene Features (Global_active_power, Global_reactive_power, etc.)
   - Zeitstempel-basierte Darstellung der Vorhersagen
   - R√ºcktransformation auf Originalskala f√ºr interpretierbare Werte

